# -*- coding: utf-8 -*-
"""mymodel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16tenZojmFumBtXxEa_IO8EU5AH2QC0e9
"""

# Commented out IPython magic to ensure Python compatibility.
# Artificial Neural Network
# Importing the libraries

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt 
from keras.callbacks import EarlyStopping

# %matplotlib inline
# Importing Data file
data = pd.read_csv('employee_attrition_test.csv')
X = data.iloc[:, :-1].values 
y = data.iloc[:, 21].values

dataset = pd.DataFrame(data)

"""
count=0
for i in range(0,34):
  print(X[i])
  print("\n")
  count+=1
print(count) 
"""

#Dataset Before Preprocessing

dataset.head()



# Handling Null Values With Imputation (Constant value = 0)
# Handel Null Values of "Age" ,"BusinessTravel" ,"DailyRate" ,"DistanceFromHome" ,"MaritalStatus" columns
#using imputation in the same column

data['Age'].fillna(value=0 ,inplace=True)
data['BusinessTravel'].fillna(value=0 ,inplace=True)
data['DailyRate'].fillna(value=0 ,inplace=True)
data['DistanceFromHome'].fillna(value=0 ,inplace=True)
data['MaritalStatus'].fillna(value=0 ,inplace=True)

dataset

# Encoding categorical data
# Label Encoding the "Gender","Department","EducationField","JobRole" ,"Over18","OverTime" Columns
from sklearn.preprocessing import LabelEncoder

l1 = LabelEncoder()

data['Department']=l1.fit_transform(dataset['Department'])
data['EducationField']=l1.fit_transform(dataset['EducationField'])
data['Gender']=l1.fit_transform(dataset['Gender'])
data['JobRole']=l1.fit_transform(dataset['JobRole'])
data['Over18']=l1.fit_transform(dataset['Over18'])
data['OverTime']=l1.fit_transform(dataset['OverTime'])

pd.DataFrame(data)

data.shape

# Encoding categorical data
# Mapping Encoding The "MaritalStatus" ,"BusinessTravel" Columns

data['MaritalStatus']=data['MaritalStatus'].replace('0',0)
data['MaritalStatus']=data['MaritalStatus'].replace('Single',1)
data['MaritalStatus']=data['MaritalStatus'].replace('Divorced',2)
data['MaritalStatus']=data['MaritalStatus'].replace('Married',3)

data['BusinessTravel']=data['BusinessTravel'].replace('0',0)
data['BusinessTravel']=data['BusinessTravel'].replace('Travel_Rarely',1)
data['BusinessTravel']=data['BusinessTravel'].replace('Non-Travel',2)
data['BusinessTravel']=data['BusinessTravel'].replace('Travel_Frequently',3)

pd.DataFrame(data)

print(dataset.info())

dataset.describe()

data

X= data.iloc[:, :-1].values
y= data.iloc[:, 21].values

y

#data=data[['DailyRate','EmployeeNumber','MonthlyIncome','MonthlyRate','HourlyRate']]
Q1=data.quantile(0.25)
Q3=data.quantile(0.75)
IQR=Q3-Q1
print(IQR)
print('\n')
print(Q1)
print('\n')
print(Q3)

print((dataset<(Q1-1.5*IQR))|(dataset>(Q3+1.5*IQR)))

X







#plt.boxplot(dataset["EmployeeNumber"])
plt.boxplot(data["MonthlyIncome"])
plt.show()





from sklearn.decomposition import PCA
pca =PCA(n_components=30)
X2=pca.fit_transform(X)

X2.shape



# Splitting the dataset into the Training set and Test set
from random import shuffle
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X2, y,test_size=.2)

X2.shape

X_test.shape

y

print(y)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

X2.shape

X2

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import SGD

opt = SGD(lr=0.001, momentum=0.9)

model=Sequential()

from tensorflow.python.keras.layers.core import Dropout
model.add(Dense(units=20,activation='relu'))
model.add(Dense(units=25,activation='relu'))

model.add(Dense(units=1,activation='sigmoid'))
model.add(Dropout(.2))
model.compile(optimizer = opt, loss = 'binary_crossentropy',metrics = ['accuracy'])

mo=model.fit(X_train, y_train, batch_size = 32, epochs = 100,verbose=1,callbacks=EarlyStopping(patience=1))

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5)
accuracy_score(y_test, y_pred)

"""making loss curv which represent loss function and epochs

"""

plt.plot(mo.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['train'],loc='upper left')

plt.plot(mo.history['accuracy'])
plt.title('model loss')
plt.ylabel('accuracy')
plt.xlabel('epochs')
plt.legend(['train'],loc='upper left')

"""making convusion matrix which represent true_positive ,true_negative ,false_positive,false_negative

"""

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)

accuracy_score(y_test, y_pred)

"""making roc curv which represent True positive and false positive"""

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

y_pred = model.predict(X_test).ravel()



nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(y_test  , y_pred)
auc_keras = auc(nn_fpr_keras, nn_tpr_keras)
plt.plot(nn_fpr_keras, nn_tpr_keras, marker='.', label='Neural Network (auc = %0.3f)' % auc_keras)

X_test.shape



